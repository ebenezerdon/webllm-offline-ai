# ğŸ–¥ï¸ ğŸ¤– WebLLM Offline AI Assistant

This is a browser-based LLM chat application that runs AI models directly in your browser using WebGPU technology, presented with a **pc-themed desktop interface**.
All processing happens locally on your device. No server required. âœ¨

## ğŸŒŸ Live URL

ğŸ”— Use the app at [https://chat.ebenezerdon.com](https://chat.ebenezerdon.com)

## âœ… Features

- ğŸ–¥ï¸ **PC Desktop Experience**: Interact with the chat app in a simulated pc environment, complete with a taskbar, draggable window, and window controls (minimize, maximize, close).
- ğŸ¤– **Run large language models** directly in your browser.
- ğŸ”„ **Choice of models** with different sizes and capabilities.
- ğŸ“Š **Progress tracking** for model downloads and progress bar.
- â„¹ï¸ **Model information** (download size, VRAM requirements, parameters).
- ğŸ“± **Responsive design** that adapts.
- ğŸ’¬ Clear feedback during download and inference, integrated into the pc UI.
- ğŸ›ï¸ Taskbar with a start button, app icon, and live clock.

## ğŸ”§ Requirements

- **Browser Support**: Chrome 113+, Edge 113+, or Firefox 118+ with WebGPU enabled.
- **Hardware**: Models work best with a dedicated GPU.
  - ğŸŸ¢ Small models: ~1GB VRAM (runs on most devices)
  - ğŸŸ  Medium models: ~6GB VRAM (dedicated GPU recommended)
  - ğŸŸ£ Large models: 10GB+ VRAM (high-end GPU required)

## ğŸ“ Project Structure

```
webllm-chat/
â”œâ”€â”€ index.html              # Main HTML file with pc desktop structure
â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ pc-theme.css   # Core CSS for the pc desktop theme and app window
â”‚   â””â”€â”€ icons.css           # SVG icons for the pc theme
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ index.js            # Main JavaScript entry point
â”‚   â”œâ”€â”€ app.js              # Core application logic for WebLLM chat
â”‚   â”œâ”€â”€ config.js           # Model configurations and constants
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ llm-model.js    # Handles LLM operations via WebLLM
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.js       # Logging utilities
â”‚       â”œâ”€â”€ ui.js           # UI helper functions (model select, progress, etc.)
â”‚       â”œâ”€â”€ db.js           # IndexedDB utilities for caching and preferences
â”‚       â””â”€â”€ pc-ui.js   # Manages pc desktop UI interactions (dragging, controls, taskbar)
â”œâ”€â”€ favicon.svg             # pc-themed favicon
â””â”€â”€ README.md               # This file
```

## ğŸš€ Development

To run the application locally:

1. Clone this repository.
2. Open `index.html` in a WebGPU-enabled browser.
3. The chat application will appear as a window on the simulated desktop.
4. Select a model from the dropdown within the app window and click "Load Model" (or allow auto-load).

## âš™ï¸ How It Works

This application uses [web-llm](https://github.com/mlc-ai/web-llm), a project that compiles LLMs to WebGPU for browser execution. The UI is structured as a pc desktop environment. When you load a model, it downloads the model weights (which may take some time). Subsequent loads use the cached version from IndexedDB.
The `pc-ui.js` script handles the visual aspects of the windowing (dragging, minimize, maximize, close simulation) and the taskbar.

## ğŸ”— Connect With the Developer

If you find this project useful, please consider:

- â­ Giving this repo a star on GitHub
- ğŸ“º Checking out my YouTube channel: [youtube.com/ebenezerdon](https://youtube.com/ebenezerdon)
- ğŸ‘¥ Connecting with me on LinkedIn: [linkedin.com/in/ebenezerdon](https://linkedin.com/in/ebenezerdon)
- ğŸ¦ Following me on X: [x.com/ebenezerDN](https://x.com/ebenezerDN)

Your support helps me continue creating open-source projects like this one! ğŸ™

## ğŸ“ License

GNU GPL v3
